{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.8. Adding more metrics to gain a better understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # conda install numpy\n",
    "import tensorflow as tf \n",
    "import matplotlib.pyplot as plt # conda install matplotlib\n",
    "import pandas as pd # conda install pandas\n",
    "import warnings\n",
    "import seaborn as sns # conda install seaborn\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and take a look at it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('airbnb new york.csv').sample(frac=1)\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data[['neighbourhood_group', 'room_type', 'minimum_nights', 'number_of_reviews', \n",
    "                 'reviews_per_month', 'calculated_host_listings_count', 'availability_365']]\n",
    "#print(features.isna().sum())\n",
    "features['reviews_per_month'] = features['reviews_per_month'].fillna(0)\n",
    "#print(features.isna().sum())\n",
    "\n",
    "onehot_neighborhood_group = pd.get_dummies(features['neighbourhood_group'])\n",
    "onehot_room_type = pd.get_dummies(features['room_type'])\n",
    "#print(onehot_room_type)\n",
    "\n",
    "features = features.drop(columns=['neighbourhood_group', 'room_type'])\n",
    "features = pd.concat([features, onehot_neighborhood_group, onehot_room_type], axis=1)\n",
    "#print(features.head())\n",
    "\n",
    "targets = data['price']\n",
    "\n",
    "train_size = int(0.7*len(data))\n",
    "X_train, X_test = features.values[:train_size, :], features.values[train_size:, :]\n",
    "y_train, y_test = targets.values[:train_size], targets.values[train_size:]\n",
    "\n",
    "print(len(X_train[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data visualization and analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = data.corr()\n",
    "cmap = sns.diverging_palette(250, 10, as_cmap=True)\n",
    "plt.figure(figsize=(8, 8))\n",
    "sns.heatmap(corr, square=True, cmap=cmap, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Tensorflow 2 Machine Learning Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearModel:\n",
    "    def __init__(self):\n",
    "        # y_pred = W*X + b\n",
    "        self.initializer = tf.keras.initializers.GlorotUniform()\n",
    "    \n",
    "    def loss(self, y, y_pred):\n",
    "        return tf.reduce_mean(tf.abs(y - y_pred))\n",
    "    \n",
    "    def train(self, X, y, lr=0.00001, epochs=20, verbose=True):\n",
    "            \n",
    "        X = np.asarray(X, dtype=np.float32)\n",
    "        y = np.asarray(y, dtype=np.float32).reshape((-1, 1)) # [1,2,3,4] -> [[1],[2],[3],[4]]\n",
    "        \n",
    "        self.W = tf.Variable(\n",
    "            initial_value=self.initializer(shape=(len(X[0]), 1), dtype='float32'))\n",
    "        self.b = tf.Variable(\n",
    "            initial_value=self.initializer(shape=(1,), dtype='float32'))\n",
    "\n",
    "        def train_step():\n",
    "            with tf.GradientTape() as t:\n",
    "                current_loss = self.loss(y, self.predict(X))\n",
    "\n",
    "            dW, db = t.gradient(current_loss, [self.W, self.b])\n",
    "            self.W.assign_sub(lr * dW) # W -= lr * dW\n",
    "            self.b.assign_sub(lr * db)\n",
    "            \n",
    "            return current_loss\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            current_loss = train_step()\n",
    "            if verbose:\n",
    "                print(f'Epoch {epoch}: Loss: {current_loss.numpy()}') # <3 eager execution\n",
    "                \n",
    "    def predict(self, X):\n",
    "        # [a, b] x [b, c]\n",
    "        # X -> [n_instances, n_features], W -> [n_features, 1]\n",
    "        return tf.matmul(X, self.W) + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearModel()\n",
    "model.train(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Layer Perceptron (Artificial Neural Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu'), # 0 or x: _____/\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def R_squared(y_true, y_pred):\n",
    "    residual = tf.reduce_sum(tf.square(y_true - y_pred))\n",
    "    total = tf.reduce_sum(tf.square(y_true - tf.reduce_mean(y_true)))\n",
    "    r2 = 1.0 - residual / total\n",
    "    return r2\n",
    "\n",
    "adam_optimizer = tf.keras.optimizers.Adam()\n",
    "loss_fn = tf.keras.losses.MAE\n",
    "model.compile(\n",
    "    optimizer=adam_optimizer,\n",
    "    loss=loss_fn,\n",
    "    metrics=[\n",
    "        tf.keras.metrics.MAE,\n",
    "        tf.keras.metrics.MSE,\n",
    "        R_squared, # -1 and 1, < 0 => useless, 0 and 1 => better close to 1\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34226 samples\n",
      "Epoch 1/10\n",
      "34226/34226 [==============================] - 4s 102us/sample - loss: 62.3858 - mean_absolute_error: 62.3858 - mean_squared_error: 47952.5156 - R_squared: 0.2783\n",
      "Epoch 2/10\n",
      "34226/34226 [==============================] - 3s 93us/sample - loss: 62.4518 - mean_absolute_error: 62.4518 - mean_squared_error: 47876.6758 - R_squared: 0.2764\n",
      "Epoch 3/10\n",
      "34226/34226 [==============================] - 3s 94us/sample - loss: 62.4206 - mean_absolute_error: 62.4206 - mean_squared_error: 47907.6992 - R_squared: 0.2848\n",
      "Epoch 4/10\n",
      "34226/34226 [==============================] - 3s 94us/sample - loss: 62.3398 - mean_absolute_error: 62.3398 - mean_squared_error: 47944.8633 - R_squared: 0.2813\n",
      "Epoch 5/10\n",
      "34226/34226 [==============================] - 3s 94us/sample - loss: 62.3424 - mean_absolute_error: 62.3424 - mean_squared_error: 47973.3086 - R_squared: 0.2847\n",
      "Epoch 6/10\n",
      "34226/34226 [==============================] - 3s 95us/sample - loss: 62.3229 - mean_absolute_error: 62.3228 - mean_squared_error: 47933.4766 - R_squared: 0.2807\n",
      "Epoch 7/10\n",
      "34226/34226 [==============================] - 3s 92us/sample - loss: 62.3539 - mean_absolute_error: 62.3539 - mean_squared_error: 47928.4570 - R_squared: 0.2797\n",
      "Epoch 8/10\n",
      "34226/34226 [==============================] - 3s 92us/sample - loss: 62.2603 - mean_absolute_error: 62.2603 - mean_squared_error: 47895.1289 - R_squared: 0.2808\n",
      "Epoch 9/10\n",
      "34226/34226 [==============================] - 3s 93us/sample - loss: 62.2815 - mean_absolute_error: 62.2815 - mean_squared_error: 47840.6289 - R_squared: 0.2809\n",
      "Epoch 10/10\n",
      "34226/34226 [==============================] - 3s 91us/sample - loss: 62.3038 - mean_absolute_error: 62.3038 - mean_squared_error: 47924.6211 - R_squared: 0.2791\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f399c43c450>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
