{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Video 2.5.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMJ1HWa5Di2eUfEAbNTCcrA"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"b39xHmYHadow","colab_type":"text"},"source":["# 2.5. Some advanced neural network approaches"]},{"cell_type":"markdown","metadata":{"id":"0Yp-ELGjanxx","colab_type":"text"},"source":["## Data loading and preprocessing"]},{"cell_type":"code","metadata":{"id":"5m3hbUcZaayJ","colab_type":"code","outputId":"2c5f97b8-45ef-4350-ed12-31c954d61edb","executionInfo":{"status":"ok","timestamp":1582829942098,"user_tz":-120,"elapsed":754,"user":{"displayName":"Vlad Ionescu","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mD29-ZiMbl1XDoZxnsE4JMUwDVrMwOwYfXSzp5tAQ=s64","userId":"05046943932183883109"}},"colab":{"base_uri":"https://localhost:8080/","height":269}},"source":["import pandas as pd\n","from google.colab import files\n","#uploaded = files.upload()\n","data = pd.read_csv('/content/preprocessed_data.csv')\n","data = data.sample(frac=1) # a bit weird\n","data.head()"],"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Winner</th>\n","      <th>title_bout</th>\n","      <th>no_of_rounds</th>\n","      <th>B_current_lose_streak</th>\n","      <th>B_current_win_streak</th>\n","      <th>B_draw</th>\n","      <th>B_avg_BODY_att</th>\n","      <th>B_avg_BODY_landed</th>\n","      <th>B_avg_CLINCH_att</th>\n","      <th>B_avg_CLINCH_landed</th>\n","      <th>B_avg_DISTANCE_att</th>\n","      <th>B_avg_DISTANCE_landed</th>\n","      <th>B_avg_GROUND_att</th>\n","      <th>B_avg_GROUND_landed</th>\n","      <th>B_avg_HEAD_att</th>\n","      <th>B_avg_HEAD_landed</th>\n","      <th>B_avg_KD</th>\n","      <th>B_avg_LEG_att</th>\n","      <th>B_avg_LEG_landed</th>\n","      <th>B_avg_PASS</th>\n","      <th>B_avg_REV</th>\n","      <th>B_avg_SIG_STR_att</th>\n","      <th>B_avg_SIG_STR_landed</th>\n","      <th>B_avg_SIG_STR_pct</th>\n","      <th>B_avg_SUB_ATT</th>\n","      <th>B_avg_TD_att</th>\n","      <th>B_avg_TD_landed</th>\n","      <th>B_avg_TD_pct</th>\n","      <th>B_avg_TOTAL_STR_att</th>\n","      <th>B_avg_TOTAL_STR_landed</th>\n","      <th>B_longest_win_streak</th>\n","      <th>B_losses</th>\n","      <th>B_avg_opp_BODY_att</th>\n","      <th>B_avg_opp_BODY_landed</th>\n","      <th>B_avg_opp_CLINCH_att</th>\n","      <th>B_avg_opp_CLINCH_landed</th>\n","      <th>B_avg_opp_DISTANCE_att</th>\n","      <th>B_avg_opp_DISTANCE_landed</th>\n","      <th>B_avg_opp_GROUND_att</th>\n","      <th>B_avg_opp_GROUND_landed</th>\n","      <th>...</th>\n","      <th>R_avg_opp_TOTAL_STR_att</th>\n","      <th>R_avg_opp_TOTAL_STR_landed</th>\n","      <th>R_total_rounds_fought</th>\n","      <th>R_total_time_fought(seconds)</th>\n","      <th>R_total_title_bouts</th>\n","      <th>R_win_by_Decision_Majority</th>\n","      <th>R_win_by_Decision_Split</th>\n","      <th>R_win_by_Decision_Unanimous</th>\n","      <th>R_win_by_KO/TKO</th>\n","      <th>R_win_by_Submission</th>\n","      <th>R_win_by_TKO_Doctor_Stoppage</th>\n","      <th>R_wins</th>\n","      <th>R_Height_cms</th>\n","      <th>R_Reach_cms</th>\n","      <th>R_Weight_lbs</th>\n","      <th>B_age</th>\n","      <th>R_age</th>\n","      <th>weight_class_Bantamweight</th>\n","      <th>weight_class_Catch Weight</th>\n","      <th>weight_class_Featherweight</th>\n","      <th>weight_class_Flyweight</th>\n","      <th>weight_class_Heavyweight</th>\n","      <th>weight_class_Light Heavyweight</th>\n","      <th>weight_class_Lightweight</th>\n","      <th>weight_class_Middleweight</th>\n","      <th>weight_class_Open Weight</th>\n","      <th>weight_class_Welterweight</th>\n","      <th>weight_class_Women's Bantamweight</th>\n","      <th>weight_class_Women's Featherweight</th>\n","      <th>weight_class_Women's Flyweight</th>\n","      <th>weight_class_Women's Strawweight</th>\n","      <th>B_Stance_Open Stance</th>\n","      <th>B_Stance_Orthodox</th>\n","      <th>B_Stance_Sideways</th>\n","      <th>B_Stance_Southpaw</th>\n","      <th>B_Stance_Switch</th>\n","      <th>R_Stance_Open Stance</th>\n","      <th>R_Stance_Orthodox</th>\n","      <th>R_Stance_Southpaw</th>\n","      <th>R_Stance_Switch</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2722</th>\n","      <td>Red</td>\n","      <td>False</td>\n","      <td>3</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.000</td>\n","      <td>1.000</td>\n","      <td>8.000000</td>\n","      <td>2.50</td>\n","      <td>13.500000</td>\n","      <td>4.0</td>\n","      <td>18.000</td>\n","      <td>11.500000</td>\n","      <td>35.500</td>\n","      <td>16.500</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.500000</td>\n","      <td>0.50</td>\n","      <td>1.50</td>\n","      <td>39.500000</td>\n","      <td>18.000000</td>\n","      <td>0.35</td>\n","      <td>1.000000</td>\n","      <td>0.500000</td>\n","      <td>0.000</td>\n","      <td>0.000000</td>\n","      <td>60.000000</td>\n","      <td>36.000000</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>10.50</td>\n","      <td>8.000000</td>\n","      <td>5.500000</td>\n","      <td>3.000000</td>\n","      <td>16.500</td>\n","      <td>6.500000</td>\n","      <td>30.500000</td>\n","      <td>19.500000</td>\n","      <td>...</td>\n","      <td>111.000000</td>\n","      <td>19.333333</td>\n","      <td>9.0</td>\n","      <td>900.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>182.88</td>\n","      <td>182.88</td>\n","      <td>240.0</td>\n","      <td>34.0</td>\n","      <td>30.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>854</th>\n","      <td>Red</td>\n","      <td>False</td>\n","      <td>5</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>5.000</td>\n","      <td>3.500</td>\n","      <td>6.250000</td>\n","      <td>4.00</td>\n","      <td>14.500000</td>\n","      <td>3.5</td>\n","      <td>38.750</td>\n","      <td>21.500000</td>\n","      <td>52.000</td>\n","      <td>23.500</td>\n","      <td>0.000000</td>\n","      <td>2.500000</td>\n","      <td>2.000000</td>\n","      <td>4.75</td>\n","      <td>0.25</td>\n","      <td>59.500000</td>\n","      <td>29.000000</td>\n","      <td>0.50</td>\n","      <td>1.000000</td>\n","      <td>3.000000</td>\n","      <td>2.000</td>\n","      <td>0.790000</td>\n","      <td>130.750000</td>\n","      <td>90.000000</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>5.25</td>\n","      <td>3.750000</td>\n","      <td>5.500000</td>\n","      <td>3.250000</td>\n","      <td>13.250</td>\n","      <td>5.500000</td>\n","      <td>3.000000</td>\n","      <td>2.500000</td>\n","      <td>...</td>\n","      <td>171.666667</td>\n","      <td>93.666667</td>\n","      <td>11.0</td>\n","      <td>1100.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>165.10</td>\n","      <td>167.64</td>\n","      <td>125.0</td>\n","      <td>27.0</td>\n","      <td>28.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2338</th>\n","      <td>Blue</td>\n","      <td>True</td>\n","      <td>5</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>17.000</td>\n","      <td>12.000</td>\n","      <td>1.333333</td>\n","      <td>1.00</td>\n","      <td>154.333333</td>\n","      <td>59.0</td>\n","      <td>6.000</td>\n","      <td>2.333333</td>\n","      <td>129.000</td>\n","      <td>39.000</td>\n","      <td>0.333333</td>\n","      <td>15.666667</td>\n","      <td>11.333333</td>\n","      <td>1.00</td>\n","      <td>0.00</td>\n","      <td>161.666667</td>\n","      <td>62.333333</td>\n","      <td>0.41</td>\n","      <td>0.333333</td>\n","      <td>2.666667</td>\n","      <td>2.000</td>\n","      <td>0.283333</td>\n","      <td>187.333333</td>\n","      <td>87.666667</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>13.00</td>\n","      <td>9.666667</td>\n","      <td>1.333333</td>\n","      <td>0.666667</td>\n","      <td>107.000</td>\n","      <td>36.333333</td>\n","      <td>0.666667</td>\n","      <td>0.333333</td>\n","      <td>...</td>\n","      <td>132.000000</td>\n","      <td>44.000000</td>\n","      <td>10.0</td>\n","      <td>929.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>167.64</td>\n","      <td>170.18</td>\n","      <td>135.0</td>\n","      <td>25.0</td>\n","      <td>33.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1795</th>\n","      <td>Blue</td>\n","      <td>False</td>\n","      <td>3</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>17.000</td>\n","      <td>9.000</td>\n","      <td>41.000000</td>\n","      <td>26.00</td>\n","      <td>202.000000</td>\n","      <td>53.0</td>\n","      <td>0.000</td>\n","      <td>0.000000</td>\n","      <td>206.000</td>\n","      <td>50.000</td>\n","      <td>0.000000</td>\n","      <td>20.000000</td>\n","      <td>20.000000</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>243.000000</td>\n","      <td>79.000000</td>\n","      <td>0.32</td>\n","      <td>0.000000</td>\n","      <td>5.000000</td>\n","      <td>0.000</td>\n","      <td>0.000000</td>\n","      <td>265.000000</td>\n","      <td>100.000000</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>61.00</td>\n","      <td>48.000000</td>\n","      <td>105.000000</td>\n","      <td>84.000000</td>\n","      <td>259.000</td>\n","      <td>112.000000</td>\n","      <td>6.000000</td>\n","      <td>6.000000</td>\n","      <td>...</td>\n","      <td>187.000000</td>\n","      <td>81.500000</td>\n","      <td>6.0</td>\n","      <td>900.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>180.34</td>\n","      <td>185.42</td>\n","      <td>135.0</td>\n","      <td>31.0</td>\n","      <td>28.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>67</th>\n","      <td>Blue</td>\n","      <td>False</td>\n","      <td>3</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>12.375</td>\n","      <td>7.625</td>\n","      <td>5.000000</td>\n","      <td>2.75</td>\n","      <td>135.250000</td>\n","      <td>53.0</td>\n","      <td>6.625</td>\n","      <td>4.625000</td>\n","      <td>122.125</td>\n","      <td>42.125</td>\n","      <td>0.000000</td>\n","      <td>12.375000</td>\n","      <td>10.625000</td>\n","      <td>1.50</td>\n","      <td>0.00</td>\n","      <td>146.875000</td>\n","      <td>60.375000</td>\n","      <td>0.40</td>\n","      <td>0.125000</td>\n","      <td>5.625000</td>\n","      <td>1.875</td>\n","      <td>0.335000</td>\n","      <td>183.375000</td>\n","      <td>90.250000</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","      <td>16.25</td>\n","      <td>10.250000</td>\n","      <td>3.500000</td>\n","      <td>2.375000</td>\n","      <td>127.125</td>\n","      <td>47.625000</td>\n","      <td>5.875000</td>\n","      <td>3.500000</td>\n","      <td>...</td>\n","      <td>97.250000</td>\n","      <td>43.250000</td>\n","      <td>9.0</td>\n","      <td>628.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>187.96</td>\n","      <td>193.04</td>\n","      <td>170.0</td>\n","      <td>30.0</td>\n","      <td>31.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows Ã— 160 columns</p>\n","</div>"],"text/plain":["     Winner  title_bout  ...  R_Stance_Southpaw  R_Stance_Switch\n","2722    Red       False  ...                  0                0\n","854     Red       False  ...                  1                0\n","2338   Blue        True  ...                  0                0\n","1795   Blue       False  ...                  0                0\n","67     Blue       False  ...                  0                0\n","\n","[5 rows x 160 columns]"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"id":"iimcdFJYikQi","colab_type":"code","colab":{}},"source":["data['Winner'] = data['Winner'].map(lambda x: 1 if x == 'Red' else 0)\n","data['title_bout'] = data['title_bout'].map(lambda x: 1 if x == 'True' else 0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WLDOHpEDlqLl","colab_type":"code","colab":{}},"source":["train_size = int(0.8*len(data))\n","features = data.drop(columns=['Winner'])\n","targets = data['Winner']\n","X_train, X_test = features.values[:train_size, :], features.values[train_size:, :]\n","y_train, y_test = targets.values[:train_size], targets.values[train_size:]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NSAcmYFHb_fZ","colab_type":"code","colab":{}},"source":["import seaborn as sns\n","import matplotlib.pyplot as plt\n","#sns.pairplot(data)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lumm_tihfHOD","colab_type":"code","colab":{}},"source":["corr = data.corr()\n","cmap = sns.diverging_palette(250, 10, as_cmap=True)\n","plt.figure(figsize=(40, 80))\n","sns.heatmap(corr[['Winner']], cmap=cmap, vmax=.3,\n","            square=True, linewidths=.5, cbar_kws={\"shrink\": .5},\n","            annot=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JWhS_-mEghM4","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SSvm9bVImAUC","colab_type":"text"},"source":["## Tensorflow ANNs"]},{"cell_type":"code","metadata":{"id":"HY8nLmdvmFDK","colab_type":"code","outputId":"df793642-d7cf-4aee-d5ec-29dc50968e61","executionInfo":{"status":"ok","timestamp":1582839827833,"user_tz":-120,"elapsed":12238,"user":{"displayName":"Vlad Ionescu","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mD29-ZiMbl1XDoZxnsE4JMUwDVrMwOwYfXSzp5tAQ=s64","userId":"05046943932183883109"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["import tensorflow as tf\n","\n","model = tf.keras.models.Sequential([\n","    tf.keras.layers.Dense(128, activation='relu'), # 0 or x: _____/\n","    tf.keras.layers.Dropout(0.2),\n","    tf.keras.layers.Dense(1, activation='sigmoid') # [0, 1]\n","])\n","\n","red = len(y_train[y_train>0])\n","blue = len(y_train) - red\n","total = len(y_train)\n","weight_for_red = total / (2 * red) \n","weight_for_blue = total / (2 * blue)\n","class_weight = {0: weight_for_blue, 1: weight_for_red}\n","print(class_weight)\n","\n","adam_optimizer = tf.keras.optimizers.Adam()\n","model.compile(\n","    optimizer=adam_optimizer,\n","    loss='binary_crossentropy',\n","    metrics=[\n","      tf.keras.metrics.TruePositives(name='tp'),\n","      tf.keras.metrics.FalsePositives(name='fp'),\n","      tf.keras.metrics.TrueNegatives(name='tn'),\n","      tf.keras.metrics.FalseNegatives(name='fn'), \n","      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n","      tf.keras.metrics.Precision(name='precision'),\n","      tf.keras.metrics.Recall(name='recall'),\n","      tf.keras.metrics.AUC(name='auc'),\n","    ]\n",")\n","\n","save_best_callback = tf.keras.callbacks.ModelCheckpoint(\n","    '/content/model-{epoch:02d}-{val_accuracy:.2f}.hdf5', \n","    monitor='val_accuracy', \n","    verbose=1,\n","    save_best_only=True, \n","    save_weights_only=False,\n","    save_frequency=1)\n","\n","model.fit(X_train, \n","          y_train,\n","          class_weight=class_weight,\n","          batch_size=64,\n","          validation_split=0.1,\n","          callbacks=[save_best_callback],\n","          epochs=50)"],"execution_count":50,"outputs":[{"output_type":"stream","text":["{0: 1.5010449320794148, 1: 0.7497390396659708}\n","WARNING:tensorflow:sample_weight modes were coerced from\n","  ...\n","    to  \n","  ['...']\n","WARNING:tensorflow:sample_weight modes were coerced from\n","  ...\n","    to  \n","  ['...']\n","Train on 2585 samples, validate on 288 samples\n","Epoch 1/50\n","2048/2585 [======================>.......] - ETA: 0s - loss: 11.0334 - tp: 706.0000 - fp: 329.0000 - tn: 360.0000 - fn: 653.0000 - accuracy: 0.5205 - precision: 0.6821 - recall: 0.5195 - auc: 0.5246\n","Epoch 00001: val_accuracy improved from -inf to 0.50694, saving model to /content/model-01-0.51.hdf5\n","2585/2585 [==============================] - 3s 1ms/sample - loss: 10.8084 - tp: 882.0000 - fp: 424.0000 - tn: 443.0000 - fn: 836.0000 - accuracy: 0.5126 - precision: 0.6753 - recall: 0.5134 - auc: 0.5151 - val_loss: 3.7268 - val_tp: 82.0000 - val_fp: 26.0000 - val_tn: 64.0000 - val_fn: 116.0000 - val_accuracy: 0.5069 - val_precision: 0.7593 - val_recall: 0.4141 - val_auc: 0.5750\n","Epoch 2/50\n","1920/2585 [=====================>........] - ETA: 0s - loss: 6.8153 - tp: 678.0000 - fp: 300.0000 - tn: 352.0000 - fn: 590.0000 - accuracy: 0.5365 - precision: 0.6933 - recall: 0.5347 - auc: 0.5457\n","Epoch 00002: val_accuracy improved from 0.50694 to 0.63542, saving model to /content/model-02-0.64.hdf5\n","2585/2585 [==============================] - 0s 73us/sample - loss: 6.3565 - tp: 911.0000 - fp: 398.0000 - tn: 469.0000 - fn: 807.0000 - accuracy: 0.5338 - precision: 0.6960 - recall: 0.5303 - auc: 0.5498 - val_loss: 3.2348 - val_tp: 163.0000 - val_fp: 70.0000 - val_tn: 20.0000 - val_fn: 35.0000 - val_accuracy: 0.6354 - val_precision: 0.6996 - val_recall: 0.8232 - val_auc: 0.5869\n","Epoch 3/50\n","2048/2585 [======================>.......] - ETA: 0s - loss: 3.8817 - tp: 767.0000 - fp: 317.0000 - tn: 384.0000 - fn: 580.0000 - accuracy: 0.5620 - precision: 0.7076 - recall: 0.5694 - auc: 0.5719\n","Epoch 00003: val_accuracy did not improve from 0.63542\n","2585/2585 [==============================] - 0s 65us/sample - loss: 3.7795 - tp: 964.0000 - fp: 385.0000 - tn: 482.0000 - fn: 754.0000 - accuracy: 0.5594 - precision: 0.7146 - recall: 0.5611 - auc: 0.5684 - val_loss: 1.8849 - val_tp: 131.0000 - val_fp: 55.0000 - val_tn: 35.0000 - val_fn: 67.0000 - val_accuracy: 0.5764 - val_precision: 0.7043 - val_recall: 0.6616 - val_auc: 0.5544\n","Epoch 4/50\n","2112/2585 [=======================>......] - ETA: 0s - loss: 2.4923 - tp: 729.0000 - fp: 327.0000 - tn: 383.0000 - fn: 673.0000 - accuracy: 0.5265 - precision: 0.6903 - recall: 0.5200 - auc: 0.5490\n","Epoch 00004: val_accuracy did not improve from 0.63542\n","2585/2585 [==============================] - 0s 64us/sample - loss: 2.3831 - tp: 909.0000 - fp: 397.0000 - tn: 470.0000 - fn: 809.0000 - accuracy: 0.5335 - precision: 0.6960 - recall: 0.5291 - auc: 0.5534 - val_loss: 1.4254 - val_tp: 121.0000 - val_fp: 52.0000 - val_tn: 38.0000 - val_fn: 77.0000 - val_accuracy: 0.5521 - val_precision: 0.6994 - val_recall: 0.6111 - val_auc: 0.5404\n","Epoch 5/50\n","2048/2585 [======================>.......] - ETA: 0s - loss: 1.5357 - tp: 726.0000 - fp: 296.0000 - tn: 393.0000 - fn: 633.0000 - accuracy: 0.5464 - precision: 0.7104 - recall: 0.5342 - auc: 0.5701\n","Epoch 00005: val_accuracy did not improve from 0.63542\n","2585/2585 [==============================] - 0s 64us/sample - loss: 1.4794 - tp: 922.0000 - fp: 375.0000 - tn: 492.0000 - fn: 796.0000 - accuracy: 0.5470 - precision: 0.7109 - recall: 0.5367 - auc: 0.5734 - val_loss: 1.0779 - val_tp: 99.0000 - val_fp: 29.0000 - val_tn: 61.0000 - val_fn: 99.0000 - val_accuracy: 0.5556 - val_precision: 0.7734 - val_recall: 0.5000 - val_auc: 0.6040\n","Epoch 6/50\n","1920/2585 [=====================>........] - ETA: 0s - loss: 1.1260 - tp: 759.0000 - fp: 273.0000 - tn: 351.0000 - fn: 537.0000 - accuracy: 0.5781 - precision: 0.7355 - recall: 0.5856 - auc: 0.5972\n","Epoch 00006: val_accuracy did not improve from 0.63542\n","2585/2585 [==============================] - 0s 67us/sample - loss: 1.0965 - tp: 950.0000 - fp: 354.0000 - tn: 513.0000 - fn: 768.0000 - accuracy: 0.5660 - precision: 0.7285 - recall: 0.5530 - auc: 0.5937 - val_loss: 0.9318 - val_tp: 109.0000 - val_fp: 35.0000 - val_tn: 55.0000 - val_fn: 89.0000 - val_accuracy: 0.5694 - val_precision: 0.7569 - val_recall: 0.5505 - val_auc: 0.6041\n","Epoch 7/50\n","1984/2585 [======================>.......] - ETA: 0s - loss: 0.9684 - tp: 643.0000 - fp: 235.0000 - tn: 443.0000 - fn: 663.0000 - accuracy: 0.5474 - precision: 0.7323 - recall: 0.4923 - auc: 0.5838\n","Epoch 00007: val_accuracy did not improve from 0.63542\n","2585/2585 [==============================] - 0s 63us/sample - loss: 0.9556 - tp: 856.0000 - fp: 298.0000 - tn: 569.0000 - fn: 862.0000 - accuracy: 0.5513 - precision: 0.7418 - recall: 0.4983 - auc: 0.5892 - val_loss: 0.8309 - val_tp: 131.0000 - val_fp: 42.0000 - val_tn: 48.0000 - val_fn: 67.0000 - val_accuracy: 0.6215 - val_precision: 0.7572 - val_recall: 0.6616 - val_auc: 0.6194\n","Epoch 8/50\n","2048/2585 [======================>.......] - ETA: 0s - loss: 0.8743 - tp: 662.0000 - fp: 225.0000 - tn: 461.0000 - fn: 700.0000 - accuracy: 0.5483 - precision: 0.7463 - recall: 0.4860 - auc: 0.6076\n","Epoch 00008: val_accuracy did not improve from 0.63542\n","2585/2585 [==============================] - 0s 65us/sample - loss: 0.8642 - tp: 834.0000 - fp: 283.0000 - tn: 584.0000 - fn: 884.0000 - accuracy: 0.5485 - precision: 0.7466 - recall: 0.4854 - auc: 0.6007 - val_loss: 0.7885 - val_tp: 129.0000 - val_fp: 47.0000 - val_tn: 43.0000 - val_fn: 69.0000 - val_accuracy: 0.5972 - val_precision: 0.7330 - val_recall: 0.6515 - val_auc: 0.6022\n","Epoch 9/50\n","1856/2585 [====================>.........] - ETA: 0s - loss: 0.7773 - tp: 631.0000 - fp: 199.0000 - tn: 431.0000 - fn: 595.0000 - accuracy: 0.5722 - precision: 0.7602 - recall: 0.5147 - auc: 0.6282\n","Epoch 00009: val_accuracy did not improve from 0.63542\n","2585/2585 [==============================] - 0s 68us/sample - loss: 0.7817 - tp: 909.0000 - fp: 292.0000 - tn: 575.0000 - fn: 809.0000 - accuracy: 0.5741 - precision: 0.7569 - recall: 0.5291 - auc: 0.6254 - val_loss: 0.7487 - val_tp: 117.0000 - val_fp: 36.0000 - val_tn: 54.0000 - val_fn: 81.0000 - val_accuracy: 0.5938 - val_precision: 0.7647 - val_recall: 0.5909 - val_auc: 0.6270\n","Epoch 10/50\n","1984/2585 [======================>.......] - ETA: 0s - loss: 0.7564 - tp: 619.0000 - fp: 156.0000 - tn: 503.0000 - fn: 706.0000 - accuracy: 0.5655 - precision: 0.7987 - recall: 0.4672 - auc: 0.6315\n","Epoch 00010: val_accuracy did not improve from 0.63542\n","2585/2585 [==============================] - 0s 67us/sample - loss: 0.7617 - tp: 865.0000 - fp: 273.0000 - tn: 594.0000 - fn: 853.0000 - accuracy: 0.5644 - precision: 0.7601 - recall: 0.5035 - auc: 0.6159 - val_loss: 0.7657 - val_tp: 115.0000 - val_fp: 35.0000 - val_tn: 55.0000 - val_fn: 83.0000 - val_accuracy: 0.5903 - val_precision: 0.7667 - val_recall: 0.5808 - val_auc: 0.6258\n","Epoch 11/50\n","1984/2585 [======================>.......] - ETA: 0s - loss: 0.7382 - tp: 575.0000 - fp: 156.0000 - tn: 512.0000 - fn: 741.0000 - accuracy: 0.5479 - precision: 0.7866 - recall: 0.4369 - auc: 0.6281\n","Epoch 00011: val_accuracy did not improve from 0.63542\n","2585/2585 [==============================] - 0s 66us/sample - loss: 0.7267 - tp: 733.0000 - fp: 199.0000 - tn: 668.0000 - fn: 985.0000 - accuracy: 0.5420 - precision: 0.7865 - recall: 0.4267 - auc: 0.6273 - val_loss: 0.7730 - val_tp: 111.0000 - val_fp: 33.0000 - val_tn: 57.0000 - val_fn: 87.0000 - val_accuracy: 0.5833 - val_precision: 0.7708 - val_recall: 0.5606 - val_auc: 0.6198\n","Epoch 12/50\n","1856/2585 [====================>.........] - ETA: 0s - loss: 0.7089 - tp: 568.0000 - fp: 148.0000 - tn: 473.0000 - fn: 667.0000 - accuracy: 0.5609 - precision: 0.7933 - recall: 0.4599 - auc: 0.6453\n","Epoch 00012: val_accuracy did not improve from 0.63542\n","2585/2585 [==============================] - 0s 69us/sample - loss: 0.7025 - tp: 795.0000 - fp: 223.0000 - tn: 644.0000 - fn: 923.0000 - accuracy: 0.5567 - precision: 0.7809 - recall: 0.4627 - auc: 0.6420 - val_loss: 0.7491 - val_tp: 132.0000 - val_fp: 45.0000 - val_tn: 45.0000 - val_fn: 66.0000 - val_accuracy: 0.6146 - val_precision: 0.7458 - val_recall: 0.6667 - val_auc: 0.6192\n","Epoch 13/50\n","1856/2585 [====================>.........] - ETA: 0s - loss: 0.6910 - tp: 592.0000 - fp: 165.0000 - tn: 469.0000 - fn: 630.0000 - accuracy: 0.5717 - precision: 0.7820 - recall: 0.4845 - auc: 0.6461\n","Epoch 00013: val_accuracy did not improve from 0.63542\n","2585/2585 [==============================] - 0s 68us/sample - loss: 0.6855 - tp: 814.0000 - fp: 209.0000 - tn: 658.0000 - fn: 904.0000 - accuracy: 0.5694 - precision: 0.7957 - recall: 0.4738 - auc: 0.6463 - val_loss: 0.7505 - val_tp: 93.0000 - val_fp: 32.0000 - val_tn: 58.0000 - val_fn: 105.0000 - val_accuracy: 0.5243 - val_precision: 0.7440 - val_recall: 0.4697 - val_auc: 0.5981\n","Epoch 14/50\n","1664/2585 [==================>...........] - ETA: 0s - loss: 0.6675 - tp: 525.0000 - fp: 134.0000 - tn: 428.0000 - fn: 577.0000 - accuracy: 0.5727 - precision: 0.7967 - recall: 0.4764 - auc: 0.6545\n","Epoch 00014: val_accuracy did not improve from 0.63542\n","2585/2585 [==============================] - 0s 72us/sample - loss: 0.6827 - tp: 828.0000 - fp: 210.0000 - tn: 657.0000 - fn: 890.0000 - accuracy: 0.5745 - precision: 0.7977 - recall: 0.4820 - auc: 0.6545 - val_loss: 0.7224 - val_tp: 95.0000 - val_fp: 33.0000 - val_tn: 57.0000 - val_fn: 103.0000 - val_accuracy: 0.5278 - val_precision: 0.7422 - val_recall: 0.4798 - val_auc: 0.6031\n","Epoch 15/50\n","1792/2585 [===================>..........] - ETA: 0s - loss: 0.6612 - tp: 575.0000 - fp: 135.0000 - tn: 463.0000 - fn: 619.0000 - accuracy: 0.5792 - precision: 0.8099 - recall: 0.4816 - auc: 0.6543\n","Epoch 00015: val_accuracy did not improve from 0.63542\n","2585/2585 [==============================] - 0s 69us/sample - loss: 0.6752 - tp: 834.0000 - fp: 208.0000 - tn: 659.0000 - fn: 884.0000 - accuracy: 0.5776 - precision: 0.8004 - recall: 0.4854 - auc: 0.6439 - val_loss: 0.7208 - val_tp: 72.0000 - val_fp: 21.0000 - val_tn: 69.0000 - val_fn: 126.0000 - val_accuracy: 0.4896 - val_precision: 0.7742 - val_recall: 0.3636 - val_auc: 0.6006\n","Epoch 16/50\n","1920/2585 [=====================>........] - ETA: 0s - loss: 0.6689 - tp: 628.0000 - fp: 162.0000 - tn: 476.0000 - fn: 654.0000 - accuracy: 0.5750 - precision: 0.7949 - recall: 0.4899 - auc: 0.6591\n","Epoch 00016: val_accuracy did not improve from 0.63542\n","2585/2585 [==============================] - 0s 68us/sample - loss: 0.6739 - tp: 853.0000 - fp: 214.0000 - tn: 653.0000 - fn: 865.0000 - accuracy: 0.5826 - precision: 0.7994 - recall: 0.4965 - auc: 0.6590 - val_loss: 0.7038 - val_tp: 102.0000 - val_fp: 31.0000 - val_tn: 59.0000 - val_fn: 96.0000 - val_accuracy: 0.5590 - val_precision: 0.7669 - val_recall: 0.5152 - val_auc: 0.6318\n","Epoch 17/50\n","1856/2585 [====================>.........] - ETA: 0s - loss: 0.6673 - tp: 598.0000 - fp: 137.0000 - tn: 460.0000 - fn: 661.0000 - accuracy: 0.5700 - precision: 0.8136 - recall: 0.4750 - auc: 0.6519\n","Epoch 00017: val_accuracy did not improve from 0.63542\n","2585/2585 [==============================] - 0s 69us/sample - loss: 0.6746 - tp: 774.0000 - fp: 199.0000 - tn: 668.0000 - fn: 944.0000 - accuracy: 0.5578 - precision: 0.7955 - recall: 0.4505 - auc: 0.6471 - val_loss: 0.7100 - val_tp: 83.0000 - val_fp: 21.0000 - val_tn: 69.0000 - val_fn: 115.0000 - val_accuracy: 0.5278 - val_precision: 0.7981 - val_recall: 0.4192 - val_auc: 0.6367\n","Epoch 18/50\n","1792/2585 [===================>..........] - ETA: 0s - loss: 0.6509 - tp: 563.0000 - fp: 136.0000 - tn: 457.0000 - fn: 636.0000 - accuracy: 0.5692 - precision: 0.8054 - recall: 0.4696 - auc: 0.6596\n","Epoch 00018: val_accuracy did not improve from 0.63542\n","2585/2585 [==============================] - 0s 70us/sample - loss: 0.6497 - tp: 837.0000 - fp: 213.0000 - tn: 654.0000 - fn: 881.0000 - accuracy: 0.5768 - precision: 0.7971 - recall: 0.4872 - auc: 0.6645 - val_loss: 0.7546 - val_tp: 114.0000 - val_fp: 32.0000 - val_tn: 58.0000 - val_fn: 84.0000 - val_accuracy: 0.5972 - val_precision: 0.7808 - val_recall: 0.5758 - val_auc: 0.6237\n","Epoch 19/50\n","2048/2585 [======================>.......] - ETA: 0s - loss: 0.6648 - tp: 694.0000 - fp: 184.0000 - tn: 504.0000 - fn: 666.0000 - accuracy: 0.5850 - precision: 0.7904 - recall: 0.5103 - auc: 0.6691\n","Epoch 00019: val_accuracy did not improve from 0.63542\n","2585/2585 [==============================] - 0s 65us/sample - loss: 0.6651 - tp: 850.0000 - fp: 226.0000 - tn: 641.0000 - fn: 868.0000 - accuracy: 0.5768 - precision: 0.7900 - recall: 0.4948 - auc: 0.6630 - val_loss: 0.7138 - val_tp: 75.0000 - val_fp: 23.0000 - val_tn: 67.0000 - val_fn: 123.0000 - val_accuracy: 0.4931 - val_precision: 0.7653 - val_recall: 0.3788 - val_auc: 0.6072\n","Epoch 20/50\n","1984/2585 [======================>.......] - ETA: 0s - loss: 0.6375 - tp: 651.0000 - fp: 149.0000 - tn: 505.0000 - fn: 679.0000 - accuracy: 0.5827 - precision: 0.8138 - recall: 0.4895 - auc: 0.6743\n","Epoch 00020: val_accuracy did not improve from 0.63542\n","2585/2585 [==============================] - 0s 64us/sample - loss: 0.6399 - tp: 835.0000 - fp: 189.0000 - tn: 678.0000 - fn: 883.0000 - accuracy: 0.5853 - precision: 0.8154 - recall: 0.4860 - auc: 0.6756 - val_loss: 0.7268 - val_tp: 101.0000 - val_fp: 26.0000 - val_tn: 64.0000 - val_fn: 97.0000 - val_accuracy: 0.5729 - val_precision: 0.7953 - val_recall: 0.5101 - val_auc: 0.6203\n","Epoch 21/50\n","1920/2585 [=====================>........] - ETA: 0s - loss: 0.6405 - tp: 591.0000 - fp: 145.0000 - tn: 508.0000 - fn: 676.0000 - accuracy: 0.5724 - precision: 0.8030 - recall: 0.4665 - auc: 0.6754\n","Epoch 00021: val_accuracy did not improve from 0.63542\n","2585/2585 [==============================] - 0s 65us/sample - loss: 0.6366 - tp: 782.0000 - fp: 183.0000 - tn: 684.0000 - fn: 936.0000 - accuracy: 0.5671 - precision: 0.8104 - recall: 0.4552 - auc: 0.6751 - val_loss: 0.7257 - val_tp: 123.0000 - val_fp: 40.0000 - val_tn: 50.0000 - val_fn: 75.0000 - val_accuracy: 0.6007 - val_precision: 0.7546 - val_recall: 0.6212 - val_auc: 0.6410\n","Epoch 22/50\n","2112/2585 [=======================>......] - ETA: 0s - loss: 0.6441 - tp: 742.0000 - fp: 199.0000 - tn: 506.0000 - fn: 665.0000 - accuracy: 0.5909 - precision: 0.7885 - recall: 0.5274 - auc: 0.6753\n","Epoch 00022: val_accuracy did not improve from 0.63542\n","2585/2585 [==============================] - 0s 62us/sample - loss: 0.6433 - tp: 910.0000 - fp: 247.0000 - tn: 620.0000 - fn: 808.0000 - accuracy: 0.5919 - precision: 0.7865 - recall: 0.5297 - auc: 0.6718 - val_loss: 0.7318 - val_tp: 129.0000 - val_fp: 39.0000 - val_tn: 51.0000 - val_fn: 69.0000 - val_accuracy: 0.6250 - val_precision: 0.7679 - val_recall: 0.6515 - val_auc: 0.6290\n","Epoch 23/50\n","1728/2585 [===================>..........] - ETA: 0s - loss: 0.6280 - tp: 589.0000 - fp: 134.0000 - tn: 447.0000 - fn: 558.0000 - accuracy: 0.5995 - precision: 0.8147 - recall: 0.5135 - auc: 0.6862\n","Epoch 00023: val_accuracy did not improve from 0.63542\n","2585/2585 [==============================] - 0s 67us/sample - loss: 0.6382 - tp: 892.0000 - fp: 222.0000 - tn: 645.0000 - fn: 826.0000 - accuracy: 0.5946 - precision: 0.8007 - recall: 0.5192 - auc: 0.6753 - val_loss: 0.7262 - val_tp: 108.0000 - val_fp: 32.0000 - val_tn: 58.0000 - val_fn: 90.0000 - val_accuracy: 0.5764 - val_precision: 0.7714 - val_recall: 0.5455 - val_auc: 0.6147\n","Epoch 24/50\n","2048/2585 [======================>.......] - ETA: 0s - loss: 0.6221 - tp: 701.0000 - fp: 161.0000 - tn: 534.0000 - fn: 652.0000 - accuracy: 0.6030 - precision: 0.8132 - recall: 0.5181 - auc: 0.6893\n","Epoch 00024: val_accuracy did not improve from 0.63542\n","2585/2585 [==============================] - 0s 65us/sample - loss: 0.6270 - tp: 857.0000 - fp: 200.0000 - tn: 667.0000 - fn: 861.0000 - accuracy: 0.5896 - precision: 0.8108 - recall: 0.4988 - auc: 0.6822 - val_loss: 0.7390 - val_tp: 104.0000 - val_fp: 33.0000 - val_tn: 57.0000 - val_fn: 94.0000 - val_accuracy: 0.5590 - val_precision: 0.7591 - val_recall: 0.5253 - val_auc: 0.6081\n","Epoch 25/50\n","2112/2585 [=======================>......] - ETA: 0s - loss: 0.6370 - tp: 658.0000 - fp: 152.0000 - tn: 578.0000 - fn: 724.0000 - accuracy: 0.5852 - precision: 0.8123 - recall: 0.4761 - auc: 0.6810\n","Epoch 00025: val_accuracy did not improve from 0.63542\n","2585/2585 [==============================] - 0s 62us/sample - loss: 0.6367 - tp: 858.0000 - fp: 193.0000 - tn: 674.0000 - fn: 860.0000 - accuracy: 0.5926 - precision: 0.8164 - recall: 0.4994 - auc: 0.6864 - val_loss: 0.7306 - val_tp: 129.0000 - val_fp: 43.0000 - val_tn: 47.0000 - val_fn: 69.0000 - val_accuracy: 0.6111 - val_precision: 0.7500 - val_recall: 0.6515 - val_auc: 0.6281\n","Epoch 26/50\n","1984/2585 [======================>.......] - ETA: 0s - loss: 0.6233 - tp: 776.0000 - fp: 199.0000 - tn: 453.0000 - fn: 556.0000 - accuracy: 0.6195 - precision: 0.7959 - recall: 0.5826 - auc: 0.6999\n","Epoch 00026: val_accuracy did not improve from 0.63542\n","2585/2585 [==============================] - 0s 64us/sample - loss: 0.6293 - tp: 947.0000 - fp: 249.0000 - tn: 618.0000 - fn: 771.0000 - accuracy: 0.6054 - precision: 0.7918 - recall: 0.5512 - auc: 0.6879 - val_loss: 0.6911 - val_tp: 77.0000 - val_fp: 19.0000 - val_tn: 71.0000 - val_fn: 121.0000 - val_accuracy: 0.5139 - val_precision: 0.8021 - val_recall: 0.3889 - val_auc: 0.6279\n","Epoch 27/50\n","1984/2585 [======================>.......] - ETA: 0s - loss: 0.6317 - tp: 699.0000 - fp: 165.0000 - tn: 499.0000 - fn: 621.0000 - accuracy: 0.6038 - precision: 0.8090 - recall: 0.5295 - auc: 0.6945\n","Epoch 00027: val_accuracy did not improve from 0.63542\n","2585/2585 [==============================] - 0s 64us/sample - loss: 0.6322 - tp: 899.0000 - fp: 217.0000 - tn: 650.0000 - fn: 819.0000 - accuracy: 0.5992 - precision: 0.8056 - recall: 0.5233 - auc: 0.6892 - val_loss: 0.7333 - val_tp: 116.0000 - val_fp: 32.0000 - val_tn: 58.0000 - val_fn: 82.0000 - val_accuracy: 0.6042 - val_precision: 0.7838 - val_recall: 0.5859 - val_auc: 0.6478\n","Epoch 28/50\n","1920/2585 [=====================>........] - ETA: 0s - loss: 0.6195 - tp: 628.0000 - fp: 135.0000 - tn: 506.0000 - fn: 651.0000 - accuracy: 0.5906 - precision: 0.8231 - recall: 0.4910 - auc: 0.7035\n","Epoch 00028: val_accuracy did not improve from 0.63542\n","2585/2585 [==============================] - 0s 63us/sample - loss: 0.6237 - tp: 852.0000 - fp: 198.0000 - tn: 669.0000 - fn: 866.0000 - accuracy: 0.5884 - precision: 0.8114 - recall: 0.4959 - auc: 0.6953 - val_loss: 0.7367 - val_tp: 103.0000 - val_fp: 29.0000 - val_tn: 61.0000 - val_fn: 95.0000 - val_accuracy: 0.5694 - val_precision: 0.7803 - val_recall: 0.5202 - val_auc: 0.6309\n","Epoch 29/50\n","2048/2585 [======================>.......] - ETA: 0s - loss: 0.6269 - tp: 645.0000 - fp: 137.0000 - tn: 567.0000 - fn: 699.0000 - accuracy: 0.5918 - precision: 0.8248 - recall: 0.4799 - auc: 0.6913\n","Epoch 00029: val_accuracy did not improve from 0.63542\n","2585/2585 [==============================] - 0s 67us/sample - loss: 0.6232 - tp: 873.0000 - fp: 192.0000 - tn: 675.0000 - fn: 845.0000 - accuracy: 0.5988 - precision: 0.8197 - recall: 0.5081 - auc: 0.6949 - val_loss: 0.7723 - val_tp: 129.0000 - val_fp: 42.0000 - val_tn: 48.0000 - val_fn: 69.0000 - val_accuracy: 0.6146 - val_precision: 0.7544 - val_recall: 0.6515 - val_auc: 0.6162\n","Epoch 30/50\n","2048/2585 [======================>.......] - ETA: 0s - loss: 0.6113 - tp: 721.0000 - fp: 167.0000 - tn: 523.0000 - fn: 637.0000 - accuracy: 0.6074 - precision: 0.8119 - recall: 0.5309 - auc: 0.7061\n","Epoch 00030: val_accuracy did not improve from 0.63542\n","2585/2585 [==============================] - 0s 64us/sample - loss: 0.6174 - tp: 946.0000 - fp: 239.0000 - tn: 628.0000 - fn: 772.0000 - accuracy: 0.6089 - precision: 0.7983 - recall: 0.5506 - auc: 0.6965 - val_loss: 0.7338 - val_tp: 119.0000 - val_fp: 39.0000 - val_tn: 51.0000 - val_fn: 79.0000 - val_accuracy: 0.5903 - val_precision: 0.7532 - val_recall: 0.6010 - val_auc: 0.6306\n","Epoch 31/50\n","2176/2585 [========================>.....] - ETA: 0s - loss: 0.6150 - tp: 776.0000 - fp: 184.0000 - tn: 524.0000 - fn: 692.0000 - accuracy: 0.5974 - precision: 0.8083 - recall: 0.5286 - auc: 0.6940\n","Epoch 00031: val_accuracy did not improve from 0.63542\n","2585/2585 [==============================] - 0s 60us/sample - loss: 0.6176 - tp: 879.0000 - fp: 202.0000 - tn: 665.0000 - fn: 839.0000 - accuracy: 0.5973 - precision: 0.8131 - recall: 0.5116 - auc: 0.6979 - val_loss: 0.7359 - val_tp: 81.0000 - val_fp: 22.0000 - val_tn: 68.0000 - val_fn: 117.0000 - val_accuracy: 0.5174 - val_precision: 0.7864 - val_recall: 0.4091 - val_auc: 0.6239\n","Epoch 32/50\n","2112/2585 [=======================>......] - ETA: 0s - loss: 0.6105 - tp: 719.0000 - fp: 137.0000 - tn: 564.0000 - fn: 692.0000 - accuracy: 0.6075 - precision: 0.8400 - recall: 0.5096 - auc: 0.7142\n","Epoch 00032: val_accuracy did not improve from 0.63542\n","2585/2585 [==============================] - 0s 61us/sample - loss: 0.6162 - tp: 880.0000 - fp: 180.0000 - tn: 687.0000 - fn: 838.0000 - accuracy: 0.6062 - precision: 0.8302 - recall: 0.5122 - auc: 0.7067 - val_loss: 0.7317 - val_tp: 86.0000 - val_fp: 22.0000 - val_tn: 68.0000 - val_fn: 112.0000 - val_accuracy: 0.5347 - val_precision: 0.7963 - val_recall: 0.4343 - val_auc: 0.6199\n","Epoch 33/50\n","2112/2585 [=======================>......] - ETA: 0s - loss: 0.6227 - tp: 702.0000 - fp: 141.0000 - tn: 577.0000 - fn: 692.0000 - accuracy: 0.6056 - precision: 0.8327 - recall: 0.5036 - auc: 0.7057\n","Epoch 00033: val_accuracy did not improve from 0.63542\n","2585/2585 [==============================] - 0s 62us/sample - loss: 0.6183 - tp: 879.0000 - fp: 182.0000 - tn: 685.0000 - fn: 839.0000 - accuracy: 0.6050 - precision: 0.8285 - recall: 0.5116 - auc: 0.7077 - val_loss: 0.7484 - val_tp: 100.0000 - val_fp: 31.0000 - val_tn: 59.0000 - val_fn: 98.0000 - val_accuracy: 0.5521 - val_precision: 0.7634 - val_recall: 0.5051 - val_auc: 0.6251\n","Epoch 34/50\n","2048/2585 [======================>.......] - ETA: 0s - loss: 0.6006 - tp: 704.0000 - fp: 135.0000 - tn: 553.0000 - fn: 656.0000 - accuracy: 0.6138 - precision: 0.8391 - recall: 0.5176 - auc: 0.7242\n","Epoch 00034: val_accuracy did not improve from 0.63542\n","2585/2585 [==============================] - 0s 62us/sample - loss: 0.6023 - tp: 873.0000 - fp: 168.0000 - tn: 699.0000 - fn: 845.0000 - accuracy: 0.6081 - precision: 0.8386 - recall: 0.5081 - auc: 0.7238 - val_loss: 0.7240 - val_tp: 101.0000 - val_fp: 27.0000 - val_tn: 63.0000 - val_fn: 97.0000 - val_accuracy: 0.5694 - val_precision: 0.7891 - val_recall: 0.5101 - val_auc: 0.6459\n","Epoch 35/50\n","1792/2585 [===================>..........] - ETA: 0s - loss: 0.5950 - tp: 716.0000 - fp: 141.0000 - tn: 456.0000 - fn: 479.0000 - accuracy: 0.6540 - precision: 0.8355 - recall: 0.5992 - auc: 0.7330\n","Epoch 00035: val_accuracy did not improve from 0.63542\n","2585/2585 [==============================] - 0s 69us/sample - loss: 0.6063 - tp: 1001.0000 - fp: 209.0000 - tn: 658.0000 - fn: 717.0000 - accuracy: 0.6418 - precision: 0.8273 - recall: 0.5827 - auc: 0.7232 - val_loss: 0.7431 - val_tp: 146.0000 - val_fp: 53.0000 - val_tn: 37.0000 - val_fn: 52.0000 - val_accuracy: 0.6354 - val_precision: 0.7337 - val_recall: 0.7374 - val_auc: 0.6272\n","Epoch 36/50\n","1920/2585 [=====================>........] - ETA: 0s - loss: 0.6029 - tp: 707.0000 - fp: 156.0000 - tn: 482.0000 - fn: 575.0000 - accuracy: 0.6193 - precision: 0.8192 - recall: 0.5515 - auc: 0.7177\n","Epoch 00036: val_accuracy did not improve from 0.63542\n","2585/2585 [==============================] - 0s 68us/sample - loss: 0.6107 - tp: 912.0000 - fp: 201.0000 - tn: 666.0000 - fn: 806.0000 - accuracy: 0.6104 - precision: 0.8194 - recall: 0.5308 - auc: 0.7122 - val_loss: 0.7100 - val_tp: 96.0000 - val_fp: 25.0000 - val_tn: 65.0000 - val_fn: 102.0000 - val_accuracy: 0.5590 - val_precision: 0.7934 - val_recall: 0.4848 - val_auc: 0.6432\n","Epoch 37/50\n","1984/2585 [======================>.......] - ETA: 0s - loss: 0.6162 - tp: 692.0000 - fp: 148.0000 - tn: 517.0000 - fn: 627.0000 - accuracy: 0.6094 - precision: 0.8238 - recall: 0.5246 - auc: 0.7018\n","Epoch 00037: val_accuracy did not improve from 0.63542\n","2585/2585 [==============================] - 0s 65us/sample - loss: 0.6150 - tp: 930.0000 - fp: 206.0000 - tn: 661.0000 - fn: 788.0000 - accuracy: 0.6155 - precision: 0.8187 - recall: 0.5413 - auc: 0.7040 - val_loss: 0.7338 - val_tp: 114.0000 - val_fp: 34.0000 - val_tn: 56.0000 - val_fn: 84.0000 - val_accuracy: 0.5903 - val_precision: 0.7703 - val_recall: 0.5758 - val_auc: 0.6418\n","Epoch 38/50\n","1728/2585 [===================>..........] - ETA: 0s - loss: 0.6058 - tp: 645.0000 - fp: 151.0000 - tn: 417.0000 - fn: 515.0000 - accuracy: 0.6146 - precision: 0.8103 - recall: 0.5560 - auc: 0.7070\n","Epoch 00038: val_accuracy did not improve from 0.63542\n","2585/2585 [==============================] - 0s 68us/sample - loss: 0.6050 - tp: 918.0000 - fp: 204.0000 - tn: 663.0000 - fn: 800.0000 - accuracy: 0.6116 - precision: 0.8182 - recall: 0.5343 - auc: 0.7147 - val_loss: 0.7537 - val_tp: 118.0000 - val_fp: 35.0000 - val_tn: 55.0000 - val_fn: 80.0000 - val_accuracy: 0.6007 - val_precision: 0.7712 - val_recall: 0.5960 - val_auc: 0.6430\n","Epoch 39/50\n","1920/2585 [=====================>........] - ETA: 0s - loss: 0.5983 - tp: 687.0000 - fp: 133.0000 - tn: 508.0000 - fn: 592.0000 - accuracy: 0.6224 - precision: 0.8378 - recall: 0.5371 - auc: 0.7219\n","Epoch 00039: val_accuracy did not improve from 0.63542\n","2585/2585 [==============================] - 0s 67us/sample - loss: 0.5991 - tp: 896.0000 - fp: 174.0000 - tn: 693.0000 - fn: 822.0000 - accuracy: 0.6147 - precision: 0.8374 - recall: 0.5215 - auc: 0.7228 - val_loss: 0.7344 - val_tp: 91.0000 - val_fp: 24.0000 - val_tn: 66.0000 - val_fn: 107.0000 - val_accuracy: 0.5451 - val_precision: 0.7913 - val_recall: 0.4596 - val_auc: 0.6371\n","Epoch 40/50\n","1920/2585 [=====================>........] - ETA: 0s - loss: 0.5970 - tp: 703.0000 - fp: 137.0000 - tn: 486.0000 - fn: 594.0000 - accuracy: 0.6193 - precision: 0.8369 - recall: 0.5420 - auc: 0.7206\n","Epoch 00040: val_accuracy did not improve from 0.63542\n","2585/2585 [==============================] - 0s 67us/sample - loss: 0.6043 - tp: 915.0000 - fp: 192.0000 - tn: 675.0000 - fn: 803.0000 - accuracy: 0.6151 - precision: 0.8266 - recall: 0.5326 - auc: 0.7183 - val_loss: 0.6967 - val_tp: 90.0000 - val_fp: 24.0000 - val_tn: 66.0000 - val_fn: 108.0000 - val_accuracy: 0.5417 - val_precision: 0.7895 - val_recall: 0.4545 - val_auc: 0.6402\n","Epoch 41/50\n","1920/2585 [=====================>........] - ETA: 0s - loss: 0.6048 - tp: 668.0000 - fp: 147.0000 - tn: 492.0000 - fn: 613.0000 - accuracy: 0.6042 - precision: 0.8196 - recall: 0.5215 - auc: 0.7104\n","Epoch 00041: val_accuracy did not improve from 0.63542\n","2585/2585 [==============================] - 0s 65us/sample - loss: 0.6057 - tp: 904.0000 - fp: 196.0000 - tn: 671.0000 - fn: 814.0000 - accuracy: 0.6093 - precision: 0.8218 - recall: 0.5262 - auc: 0.7124 - val_loss: 0.7370 - val_tp: 113.0000 - val_fp: 33.0000 - val_tn: 57.0000 - val_fn: 85.0000 - val_accuracy: 0.5903 - val_precision: 0.7740 - val_recall: 0.5707 - val_auc: 0.6374\n","Epoch 42/50\n","1920/2585 [=====================>........] - ETA: 0s - loss: 0.6039 - tp: 677.0000 - fp: 142.0000 - tn: 501.0000 - fn: 600.0000 - accuracy: 0.6135 - precision: 0.8266 - recall: 0.5301 - auc: 0.7153\n","Epoch 00042: val_accuracy did not improve from 0.63542\n","2585/2585 [==============================] - 0s 67us/sample - loss: 0.5993 - tp: 908.0000 - fp: 182.0000 - tn: 685.0000 - fn: 810.0000 - accuracy: 0.6162 - precision: 0.8330 - recall: 0.5285 - auc: 0.7228 - val_loss: 0.7558 - val_tp: 111.0000 - val_fp: 34.0000 - val_tn: 56.0000 - val_fn: 87.0000 - val_accuracy: 0.5799 - val_precision: 0.7655 - val_recall: 0.5606 - val_auc: 0.6372\n","Epoch 43/50\n","2112/2585 [=======================>......] - ETA: 0s - loss: 0.5928 - tp: 789.0000 - fp: 178.0000 - tn: 543.0000 - fn: 602.0000 - accuracy: 0.6307 - precision: 0.8159 - recall: 0.5672 - auc: 0.7342\n","Epoch 00043: val_accuracy improved from 0.63542 to 0.64236, saving model to /content/model-43-0.64.hdf5\n","2585/2585 [==============================] - 0s 66us/sample - loss: 0.5970 - tp: 972.0000 - fp: 216.0000 - tn: 651.0000 - fn: 746.0000 - accuracy: 0.6279 - precision: 0.8182 - recall: 0.5658 - auc: 0.7283 - val_loss: 0.7385 - val_tp: 136.0000 - val_fp: 41.0000 - val_tn: 49.0000 - val_fn: 62.0000 - val_accuracy: 0.6424 - val_precision: 0.7684 - val_recall: 0.6869 - val_auc: 0.6454\n","Epoch 44/50\n","2048/2585 [======================>.......] - ETA: 0s - loss: 0.5998 - tp: 785.0000 - fp: 188.0000 - tn: 496.0000 - fn: 579.0000 - accuracy: 0.6255 - precision: 0.8068 - recall: 0.5755 - auc: 0.7170\n","Epoch 00044: val_accuracy did not improve from 0.64236\n","2585/2585 [==============================] - 0s 66us/sample - loss: 0.6002 - tp: 962.0000 - fp: 220.0000 - tn: 647.0000 - fn: 756.0000 - accuracy: 0.6224 - precision: 0.8139 - recall: 0.5600 - auc: 0.7179 - val_loss: 0.7397 - val_tp: 99.0000 - val_fp: 23.0000 - val_tn: 67.0000 - val_fn: 99.0000 - val_accuracy: 0.5764 - val_precision: 0.8115 - val_recall: 0.5000 - val_auc: 0.6449\n","Epoch 45/50\n","2112/2585 [=======================>......] - ETA: 0s - loss: 0.5950 - tp: 717.0000 - fp: 136.0000 - tn: 577.0000 - fn: 682.0000 - accuracy: 0.6127 - precision: 0.8406 - recall: 0.5125 - auc: 0.7341\n","Epoch 00045: val_accuracy did not improve from 0.64236\n","2585/2585 [==============================] - 0s 63us/sample - loss: 0.5994 - tp: 891.0000 - fp: 168.0000 - tn: 699.0000 - fn: 827.0000 - accuracy: 0.6151 - precision: 0.8414 - recall: 0.5186 - auc: 0.7319 - val_loss: 0.7288 - val_tp: 94.0000 - val_fp: 28.0000 - val_tn: 62.0000 - val_fn: 104.0000 - val_accuracy: 0.5417 - val_precision: 0.7705 - val_recall: 0.4747 - val_auc: 0.6351\n","Epoch 46/50\n","1856/2585 [====================>.........] - ETA: 0s - loss: 0.6048 - tp: 685.0000 - fp: 154.0000 - tn: 474.0000 - fn: 543.0000 - accuracy: 0.6245 - precision: 0.8164 - recall: 0.5578 - auc: 0.7201\n","Epoch 00046: val_accuracy did not improve from 0.64236\n","2585/2585 [==============================] - 0s 68us/sample - loss: 0.5962 - tp: 959.0000 - fp: 216.0000 - tn: 651.0000 - fn: 759.0000 - accuracy: 0.6228 - precision: 0.8162 - recall: 0.5582 - auc: 0.7256 - val_loss: 0.7385 - val_tp: 104.0000 - val_fp: 27.0000 - val_tn: 63.0000 - val_fn: 94.0000 - val_accuracy: 0.5799 - val_precision: 0.7939 - val_recall: 0.5253 - val_auc: 0.6310\n","Epoch 47/50\n","2048/2585 [======================>.......] - ETA: 0s - loss: 0.6026 - tp: 688.0000 - fp: 141.0000 - tn: 571.0000 - fn: 648.0000 - accuracy: 0.6147 - precision: 0.8299 - recall: 0.5150 - auc: 0.7307\n","Epoch 00047: val_accuracy did not improve from 0.64236\n","2585/2585 [==============================] - 0s 65us/sample - loss: 0.5944 - tp: 931.0000 - fp: 192.0000 - tn: 675.0000 - fn: 787.0000 - accuracy: 0.6213 - precision: 0.8290 - recall: 0.5419 - auc: 0.7363 - val_loss: 0.7356 - val_tp: 132.0000 - val_fp: 43.0000 - val_tn: 47.0000 - val_fn: 66.0000 - val_accuracy: 0.6215 - val_precision: 0.7543 - val_recall: 0.6667 - val_auc: 0.6353\n","Epoch 48/50\n","2048/2585 [======================>.......] - ETA: 0s - loss: 0.5777 - tp: 795.0000 - fp: 153.0000 - tn: 525.0000 - fn: 575.0000 - accuracy: 0.6445 - precision: 0.8386 - recall: 0.5803 - auc: 0.7465\n","Epoch 00048: val_accuracy did not improve from 0.64236\n","2585/2585 [==============================] - 0s 62us/sample - loss: 0.5881 - tp: 972.0000 - fp: 190.0000 - tn: 677.0000 - fn: 746.0000 - accuracy: 0.6379 - precision: 0.8365 - recall: 0.5658 - auc: 0.7380 - val_loss: 0.7159 - val_tp: 105.0000 - val_fp: 25.0000 - val_tn: 65.0000 - val_fn: 93.0000 - val_accuracy: 0.5903 - val_precision: 0.8077 - val_recall: 0.5303 - val_auc: 0.6527\n","Epoch 49/50\n","1984/2585 [======================>.......] - ETA: 0s - loss: 0.5967 - tp: 749.0000 - fp: 148.0000 - tn: 514.0000 - fn: 573.0000 - accuracy: 0.6366 - precision: 0.8350 - recall: 0.5666 - auc: 0.7298\n","Epoch 00049: val_accuracy did not improve from 0.64236\n","2585/2585 [==============================] - 0s 64us/sample - loss: 0.5995 - tp: 998.0000 - fp: 207.0000 - tn: 660.0000 - fn: 720.0000 - accuracy: 0.6414 - precision: 0.8282 - recall: 0.5809 - auc: 0.7277 - val_loss: 0.7402 - val_tp: 110.0000 - val_fp: 30.0000 - val_tn: 60.0000 - val_fn: 88.0000 - val_accuracy: 0.5903 - val_precision: 0.7857 - val_recall: 0.5556 - val_auc: 0.6293\n","Epoch 50/50\n","2048/2585 [======================>.......] - ETA: 0s - loss: 0.5911 - tp: 717.0000 - fp: 150.0000 - tn: 556.0000 - fn: 625.0000 - accuracy: 0.6216 - precision: 0.8270 - recall: 0.5343 - auc: 0.7348\n","Epoch 00050: val_accuracy did not improve from 0.64236\n","2585/2585 [==============================] - 0s 64us/sample - loss: 0.5856 - tp: 933.0000 - fp: 177.0000 - tn: 690.0000 - fn: 785.0000 - accuracy: 0.6279 - precision: 0.8405 - recall: 0.5431 - auc: 0.7402 - val_loss: 0.7635 - val_tp: 128.0000 - val_fp: 50.0000 - val_tn: 40.0000 - val_fn: 70.0000 - val_accuracy: 0.5833 - val_precision: 0.7191 - val_recall: 0.6465 - val_auc: 0.6094\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fd4143a5d30>"]},"metadata":{"tags":[]},"execution_count":50}]},{"cell_type":"code","metadata":{"id":"f0c7aK-ToX8i","colab_type":"code","outputId":"33bb57f4-5b9e-434c-a472-6932f9d3f939","executionInfo":{"status":"ok","timestamp":1582839913301,"user_tz":-120,"elapsed":1957,"user":{"displayName":"Vlad Ionescu","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mD29-ZiMbl1XDoZxnsE4JMUwDVrMwOwYfXSzp5tAQ=s64","userId":"05046943932183883109"}},"colab":{"base_uri":"https://localhost:8080/","height":228}},"source":["import numpy as np\n","model = tf.keras.models.load_model('/content/model-43-0.64.hdf5')\n","model.evaluate(X_test, y_test)\n","#np.round(model.predict(X_test))"],"execution_count":52,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Sequential models without an `input_shape` passed to the first layer cannot reload their optimizer state. As a result, your model isstarting with a freshly initialized optimizer.\n","719/719 [==============================] - 1s 1ms/sample - loss: 0.6553 - tp: 285.0000 - fp: 101.0000 - tn: 154.0000 - fn: 179.0000 - accuracy: 0.6106 - precision: 0.7383 - recall: 0.6142 - auc: 0.6447\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[0.6552500779506063,\n"," 285.0,\n"," 101.0,\n"," 154.0,\n"," 179.0,\n"," 0.61057025,\n"," 0.738342,\n"," 0.61422414,\n"," 0.64474726]"]},"metadata":{"tags":[]},"execution_count":52}]},{"cell_type":"code","metadata":{"id":"CbzCqR9OmUnW","colab_type":"code","colab":{}},"source":["!pip install --upgrade tensorflow"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gOMUf2HmmW0c","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}